# Lecture 5 Value Function Approximation

# 课时4 值函数近似 2018.03.20

## 7. 介绍（Introduction）

到目前为止我们介绍了基于查表（lookup table）的值函数，这里每个状态都有一个对应条目，$V(s)$，或每个状态-动作对都有一个对应的条目，$Q(s,a)$。然而，这种方法可能不适合处理动作空间或状态空间非常大、或那些我们希望快速学习每个状态估计值的情况。函数近似是解决这个问题的常用办法：
$$
v_{\pi}(s) \approx \hat{v}(s,\mathbf{w}) \text{ or } q_{\pi}(s,a) \approx \hat{q}(s,a,\mathbf{w})，
$$
这里 $\mathbf{w}$ 通常指近似函数的参数。以下是常见的近似函数：

$\bullet$ 特征的线性组合（Linear combinations of features）

$\bullet$ 神经网络（Neural networks）

$\bullet$ 决策树（Decision trees）

$\bullet$ 最近邻（Nearest neighbors）

$\bullet$ 傅立叶/小波基（Fourier / wavelet bases）

我们讲进一步讨论可导近似函数：线性特征表示和神经网络，接下来的部分会提到要求函数可导的原因。

## 8. 线性特征表示（Linear Feature Representations）

在线性特征表示中，我们用一个特征向量去表示一个状态：
$$
x(s)=[x_1(s)\ x_2(s)\ ...\ x_n(s)]，
$$

然后我们用特征的线性组合来近似值函数：
$$
\hat{v}(s,\mathbf{w})=x(s)^{\text{T}}\mathbf{w}=\sum_{j=1}^n x_j(s)\mathbf{w}_j。
$$

我们定义（二次的）目标函数（也被称为损失函数）为：
$$
J(\mathbf{w})=\mathbb{E}_ {\pi}[(v_{\pi}(s)-\hat{v}(s,\mathbf{w}))^2]。
$$

### 8.1 梯度下降（Gradient Descent）

梯度下降（gradient descent）是最小化上述目标函数的一种常用方法。图1提供了直观的说明：我们从某个特定的点 $x_0$ 开始，对应于参数 $w$ 的某个初始值；然后计算在 $x_0$ 处的梯度，它告诉我们目标函数增加速度最快的方向；为了最小化我们的目标函数，我们沿着梯度向量的负方向以一定的步长前进，到达 $x_1$；将这个过程重复进行，直到到达某个收敛标准。

# 图1

这个方法可以被总结为：
$$
\nabla_{\text{w}}J(\text{w})=[\frac{\partial J(\text{w})}{\partial \text{w}_1}\ \frac{\partial J(\text{w})}{\partial \text{w}_2}\ ...\ \frac{\partial J(\text{w})}{\partial \text{w}_n}] \quad\text{compute the gradient}
$$

$$
\Delta\text{w}=-\frac{1}{2}\alpha\nabla_{\text{w}}J(\text{w}) \quad\text{compute an update step using gradient descent}
$$

$$
\text{w} \leftarrow \text{w}+\Delta\text{w} \quad\text{take a step towards the local minimum}
$$

### 8.2 随机梯度下降（Stochastic Gradient Descent）