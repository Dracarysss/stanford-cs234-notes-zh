# Lecture 11&12 Exploration and Exploitation

# 课时11&12 探索与利用 2019.02.20

## 1. 介绍（Introduction）

我们之前讨论过强化学习算法的设计，特别地，除了渐近收敛之外，我们还希望获得良好的性能。在教育、医疗或机器人等许多实际应用中，渐近收敛速度并不是比较强化学习算法的有效指标。为实现良好的现实世界中的表现，我们希望能够快速收敛到好的策略，这有赖于良好的策略探索。

在线决策涉及到探索（exploration）与利用（exploitation）之间的基本权衡。利用（通过最大化未来收益来）制定最佳的可能的策略，而探索则采取次优动作来收集信息。虽然次优动作必然会导致近期的奖励减少，但它可能使得我们学习更好的策略，从长远来看能够改进策略。