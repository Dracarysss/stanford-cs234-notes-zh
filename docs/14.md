# Lecture 14 Model Based RL, Monte-Carlo Tree Search

# 课时14 基于模型的强化学习，蒙特卡洛树搜索 2019.03.06

## 1. 介绍（Introduction）

本节课我们讨论基于模型的强化学习与基于仿真的树搜索方法。到目前为止我们已经讨论了从经历中尝试学习值函数或策略的方法，与这些方法相反，基于模型的方法首先从经历中学习环境的模型，然后使用这个模型做出规划和行动。基于模型的方法在某些情况下有更高的采样效率和更快的收敛速度。我们还将讨论 MCTS 及其变体，它们可以用于针对给出的模型做出规划。MCTS 是 AlphoGo 成功背后的主要思想之一。

**图一**

## 2. 模型学习（Model Learning）

我们用 $<S,A,R,T,\gamma>$ 来表示一个 MDP 的模型，由 $\mu$ 参数化。